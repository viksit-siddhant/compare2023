{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from wav2vec2 import RequestsDataset, EmotionDataset, AudioModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from bert import TranscriptData, Classifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "tqdm.pandas()\n",
    "train_df = pd.read_csv('HCC/lab/train.csv')\n",
    "develdf = pd.read_csv('HCC/lab/devel.csv')\n",
    "testdf = pd.read_csv('HCC/lab/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = RequestsDataset.get_le(train_df,target='request')\n",
    "devel = RequestsDataset(develdf, data_path='HCC/wav/',le=le,max_sec=30,test=True,target='request')\n",
    "test = RequestsDataset(testdf, data_path='HCC/wav/',max_sec=30, test=True,target='request')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'req_ckpts/wav2vec2-com.ckpt'\n",
    "model = AudioModel(2)\n",
    "devel_loader = torch.utils.data.DataLoader(devel, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=16, shuffle=False)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    accelerator='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = devel.labels\n",
    "\n",
    "preds = trainer.predict(model,devel_loader,ckpt_path=ckpt_path)\n",
    "y_hat = torch.cat(preds).detach().cpu().numpy()\n",
    "print(recall_score(y,y_hat.argmax(axis=-1),average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = trainer.predict(model,test_loader,ckpt_path=ckpt_path)\n",
    "test_preds = torch.cat(test_preds).detach().cpu().numpy()\n",
    "testdf['request'] = le.inverse_transform(test_preds.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.to_csv('intermediate.csv',index=False)\n",
    "bert_model = Classifier.load_from_checkpoint('distilbert_com/distil-com.ckpt')\n",
    "isinstance(bert_model,pl.LightningModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "traindata = TranscriptData(train_df, transcript_path='HCC/transcripts',target='complaint')\n",
    "devdata = TranscriptData(develdf, transcript_path='HCC/transcripts',test=True,target='complaint',le=traindata.le)\n",
    "testdata = TranscriptData(testdf, transcript_path='HCC/transcripts',test=True,target='complaint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel_loader = torch.utils.data.DataLoader(devdata, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(testdata, batch_size=16, shuffle=False)\n",
    "\n",
    "bert_model = bert_model.to('cuda:0')\n",
    "preds = []\n",
    "for batch in tqdm(devel_loader):\n",
    "    x0, x1= batch\n",
    "    x0 = {k:v.to('cuda:0') for k,v in x0.items()}\n",
    "    x1 = {k:v.to('cuda:0') for k,v in x1.items()}\n",
    "    y_hat = bert_model(x0,x1)\n",
    "    preds.append(y_hat.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = devdata.df['label'].values\n",
    "y_hat = np.concatenate(preds).argmax(axis=-1)\n",
    "print(recall_score(labels,y_hat,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for batch in tqdm(test_loader):\n",
    "    x0, x1= batch\n",
    "    x0 = {k:v.to('cuda:0') for k,v in x0.items()}\n",
    "    x1 = {k:v.to('cuda:0') for k,v in x1.items()}\n",
    "    y_hat = bert_model(x0,x1)\n",
    "    preds.append(y_hat.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.read_csv('intermediate.csv')\n",
    "y_hat = np.concatenate(preds).argmax(axis=-1)\n",
    "testdf['complaint'] = traindata.le.inverse_transform(y_hat)\n",
    "submission = testdf[['filename','complaint','request']]\n",
    "submission.to_csv('HCC.csv',index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "develdf = pd.read_csv('emotions/lab/devel.csv')\n",
    "testdf = pd.read_csv('emotions/lab/test.csv')\n",
    "dev_emotions = EmotionDataset(develdf, data_path='emotions/raw/wav/', test=True)\n",
    "test_emotions = EmotionDataset(testdf, data_path='emotions/raw/wav/', test=True)\n",
    "\n",
    "ckpt_path = 'ckpts/epoch=6-step=9261.ckpt'\n",
    "model = AudioModel(9,task='emotions')\n",
    "devel_loader = torch.utils.data.DataLoader(dev_emotions, batch_size=16, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_emotions, batch_size=16, shuffle=False)\n",
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    accelerator='gpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(model,test_loader,ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.sigmoid(torch.cat(preds)).detach().cpu().numpy()\n",
    "print(y_hat.shape)\n",
    "submission = testdf[['filename']].copy()\n",
    "labels = list(testdf.columns[1:])\n",
    "for i in range(len(labels)):\n",
    "    submission[labels[i]] = y_hat[:,i].reshape(-1)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('emotions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMPARE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
